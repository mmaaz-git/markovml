{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PyTorch models with MarkovML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`markovml` supports PyTorch models that have been constructed using `torch.nn.Sequential`, with only ReLU and linear layers. In order to use a classifier, you must wrap the `Sequential` model in a `SequentialClassifier` class, which will indicate to `markovml` to also construct the piecewise-linear approximation for the softmax function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the package to your Python path\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from markovml.markovml import MarkovReward\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential\n",
    "from markovml.utils.models_ext import SequentialClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to help us train a simple neural network. This code is not terribly important -- you would just be using your own training loop anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_nn(model, X, y, is_classifier=False, num_classes=None, epochs=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    if is_classifier:\n",
    "        if num_classes==2:\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    if is_classifier:\n",
    "        y_tensor = torch.LongTensor(y) if num_classes>2 else torch.FloatTensor(y).view(-1, 1)\n",
    "    else:\n",
    "        y_tensor = torch.FloatTensor(y)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_tensor)\n",
    "        loss = criterion(output, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {i+1} loss: {loss.item()}\")\n",
    "\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple neural network regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.18397751450538635\n",
      "Epoch 2 loss: 0.1828496903181076\n",
      "Epoch 3 loss: 0.18173320591449738\n",
      "Epoch 4 loss: 0.1806282103061676\n",
      "Epoch 5 loss: 0.17953632771968842\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(1000, 2)  # 2 features for example\n",
    "y = np.random.rand(1000).reshape(-1, 1)\n",
    "\n",
    "# Create and train transition model\n",
    "reg = Sequential(\n",
    "    nn.Linear(2, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, 1)\n",
    ")\n",
    "reg = train_simple_nn(reg, X, y, is_classifier=False, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.7392209768295288\n",
      "Epoch 2 loss: 0.7388524413108826\n",
      "Epoch 3 loss: 0.7384860515594482\n",
      "Epoch 4 loss: 0.7381219267845154\n",
      "Epoch 5 loss: 0.7377598881721497\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(1000, 2)  # 2 features for example\n",
    "y = np.random.randint(0, 2, size=1000)\n",
    "\n",
    "# Create and train transition model\n",
    "clf = Sequential(\n",
    "    nn.Linear(2, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, 1)\n",
    ")\n",
    "clf = train_simple_nn(clf, X, y, is_classifier=True, num_classes=2, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating a neural network regressor into `markovml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try integrating the regressor. We build a simple two-state Markov reward process and set one of the rewards equal to the output of the neural network regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2026-11-23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'optimal',\n",
       " 'objective': 87.49932597080857,\n",
       " 'values': {'pi': [0.5, 0.5],\n",
       "  'P': [[0.5, 0.5], [0.5, 0.5]],\n",
       "  'r': [5.0, 0.2499595582485199],\n",
       "  'v': [89.87434619168431, 85.12430574993284],\n",
       "  'features': [0.5664458887997081, 0.44065540800513275],\n",
       "  'ml_outputs': [[0.2499595582485199]]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrp = MarkovReward(n_states=2, n_features=2, pi=[0.5,0.5], P=[[0.5,0.5],[0.5,0.5]])\n",
    "mrp.add_ml_model(reg)\n",
    "mrp.set_r([5, mrp.ml_outputs[0][0]])\n",
    "\n",
    "for f in mrp.features.values():\n",
    "    f.LB = -1\n",
    "    f.UB = 1\n",
    "\n",
    "mrp.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating a neural network classifier into `markovml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try building another Markov reward process but by integrating the classifier, and setting some probabilities to be functions of the output of the classifier. A *very important* thing to note is that the way we set up the classifier is that it does not have a softmax layer at the end. This is the common way to set up a classifier in PyTorch: use the cross-entropy loss (which only requires the logits, not probabilities), and then at inference time, apply the softmax function to the output. In order to get around this issue, we need to wrap our classifier in a `SequentialClassifier` class, which will add a softmax layer at the end. It also signals to `markovml` that this is a classifier and hence tells it to construct the piecewise-linear approximation for the softmax function and also applies appropriate bounds to the outputs. If you don't do this, it will not work properly!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to emphasize it again: if you intend to use a `Sequential` model as a classifier, **you must wrap it in a `SequentialClassifier` class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SequentialClassifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'optimal',\n",
       " 'objective': 169.16674401365805,\n",
       " 'values': {'pi': [0.5, 0.5],\n",
       "  'P': [[0.0, 1.0000009568699972], [0.0, 1.0]],\n",
       "  'r': [10.0, 5.0],\n",
       "  'v': [171.6668213606494, 166.66666666666666],\n",
       "  'features': [-1.0, -1.0],\n",
       "  'ml_outputs': [[1.0000009568699972]]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrp = MarkovReward(n_states=2, n_features=2, pi=[0.5,0.5], r=[10, 5])\n",
    "mrp.add_ml_model(clf)\n",
    "mrp.set_P([[1 - mrp.ml_outputs[0][0], mrp.ml_outputs[0][0]], [0, 1]])\n",
    "\n",
    "for f in mrp.features.values():\n",
    "    f.LB = -1\n",
    "    f.UB = 1\n",
    "\n",
    "mrp.optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
