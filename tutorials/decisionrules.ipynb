{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a \"model\" to build *decision rules*, which are a series of \"if-then\" rules. These can be used to encode stratified values from the empirical literature. Often, in the literature, heterogenous parameters are specified for different subsets in the data. For example: if age is less than 18, then the mortality is 10%, if the age is between 18 and 30, then the mortality is 20%, and so on. This sort of series of logical implications is also MILP-representable, so we can employ our methods for it. The `DecisionRules` class helps to build such models and embed them into a Markov process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the package to your Python path\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from markovml.utils.models_ext import DecisionRules\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Decision Rules Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DecisionRules` model is built by specifying, in natural language, the rules. In order to parse the rules, we first need to specify the features that the rules will be based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'income']\n",
    "model = DecisionRules(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can specify the rules and \"fit\" the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<markovml.utils.models_ext.DecisionRules at 0x12fc81710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = [\n",
    "    \"if age > 20 then 2.5\",\n",
    "    \"if income >= 50000 and age < 30 then -1.0\",\n",
    "    \"else 0.0\"\n",
    "]\n",
    "model.fit(rules=rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can \"predict\" the model by passing in a `np.array` of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5, 0. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[25,100000], [19,30000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the first row yields 2.5 because the age is greater than 20, and the second row yields 0.0 because none of the rules are satisfied so it falls back to the \"else\" case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass a list of dictionaries of values to the `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5, 0. ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([{'age': 25, 'income': 100000}, {'age': 19, 'income': 30000}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There must always be an \"else\" case when fitting the model. As well, the value that is returned is the *first* rule that is satisfied. Here's an example where that is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<markovml.utils.models_ext.DecisionRules at 0x13a5a3410>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['age']\n",
    "model = DecisionRules(features)\n",
    "rules = [\n",
    "    \"if age > 65 then 3.0\",\n",
    "    \"if age > 25 then 2.0\",\n",
    "    \"if age > 12 then 1.5\",\n",
    "    \"else 1.0\"\n",
    "]\n",
    "model.fit(rules=rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above rules can be interpreted as age-wise prices. Clearly, anyone that meets the first rule also meets the second rule, and so on. However, we always return the first satisfied rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3. , 2. , 1.5, 1. ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([{'age': 70}, {'age': 30}, {'age': 20}, {'age': 10}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for the rules is always: \"if {feature} {op} {value} and {feature} {op} {value} ... then {value}\". The allowed operators are: `>`, `>=`, `<`, `<=`, and `==`. The \"else\" case is always the last case. The reason why specifying the feature names is important is to parse the rules properly, as well as to encode the rules into the MILP formulation later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating into a Markov model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written the MILP formulation for the `DecisionRules` model. It satisfies all the same properties as when using it for predictions; for example, it is always the value of the first satisfied rule that is returned. In order to encode this series of rules into a MILP, we formulate a series of logical implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of integrating the `DecisionRules` model into a Markov process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'optimal',\n",
       " 'objective': 8.25,\n",
       " 'values': {'pi': [0.7, 0.3],\n",
       "  'Q': [[0.6, 0.2], [-0.0, 0.9]],\n",
       "  'v': [7.5, 10.0],\n",
       "  'features': [20.0, 1.0],\n",
       "  'ml_outputs': [[0.2]]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from markovml.markovml import MarkovHitting\n",
    "from gurobipy import GRB\n",
    "markov = MarkovHitting(n_states=3, n_features=2, n_transient=2, pi=[0.7, 0.3])\n",
    "\n",
    "# decision rules model for probabilities\n",
    "dr = DecisionRules(['age', 'sex'])\n",
    "dr.fit(rules = [\n",
    "    \"if sex == 1 and age > 20 then 0.1\",\n",
    "    \"if sex == 0 and age > 20 then 0.05\",\n",
    "    \"if sex == 1 and age <= 20 then 0.2\",\n",
    "    \"if sex == 0 and age <= 20 then 0.15\",\n",
    "    \"else 0.0\"\n",
    "])\n",
    "\n",
    "markov.add_ml_model(dr)\n",
    "\n",
    "markov.set_Q([[0.8 - markov.ml_outputs[0][0], markov.ml_outputs[0][0]],\n",
    "              [0, 0.9]])\n",
    "\n",
    "# fix features to be men from 15 to 65\n",
    "markov.add_feature_constraint(markov.features[0] >= 15) # note age is feature[0]\n",
    "markov.add_feature_constraint(markov.features[0] <= 65)\n",
    "markov.features[1].vType = GRB.BINARY # note feature[1] is sex bc of order\n",
    "markov.add_feature_constraint(markov.features[1] == 1)\n",
    "\n",
    "markov.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, over the specified feature space, we can expect at most 8.25 steps on average to hit the absorbing state (say, death)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
